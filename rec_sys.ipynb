{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-363f245b-620a-4d3e-9e43-792c6a6dc8ac",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#source shell code (for peel) for greene? \n",
    "export HADOOP_EXE='/usr/bin/hadoop'\n",
    "\n",
    "module load python/gcc/3.7.9\n",
    "\n",
    "alias hfs=\"$HADOOP_EXE fs\"\n",
    "alias spark-submit='PYSPARK_PYTHON=$(which python) spark-submit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loop version hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-a9cb779b-53cf-4c08-bfbd-9a865cdb5f6f",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Your recommendation model should use Spark's alternating least squares (ALS) method to learn latent factor representations for users and items.\n",
    "\n",
    "#user_id  | count | track_id   \n",
    "\n",
    "#Run final code in peel cluster\n",
    "#Run numpy code in greene cluster\n",
    "#**Set up source shell_setup.sh in repo**\n",
    "#hdfs:/user/bm106/pub/MSD\n",
    "#Go under correct directory\n",
    "#spark-submit rec_sys.py --conf \"spark.blacklist.enabled=false\"\n",
    "#spark-submit --driver-memory=4g --executor-memory=4g --executor-cores=50 'pyfile'\n",
    "#conf.set(\"spark.blacklist.enabled\",\"false\") #if in code itself\n",
    "#import umap #seems to be local \n",
    "import sys\n",
    "import getpass \n",
    "import random\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.evaluation import RankingMetrics #May want to use MAP\n",
    "from pyspark.ml.evaluation import RegressionEvaluator #RMSE\n",
    "from pyspark.ml.recommendation import ALS #Alternating least squares\n",
    "from pyspark.sql import Row, Window\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import explode, col, expr\n",
    "import pyspark.sql.functions as pyF\n",
    "\n",
    "def main (spark, netID):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    spark : SparkSession object\n",
    "    netID : string, netID of student to find files in HDFS\n",
    "    '''\n",
    "    training=spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_train_new.parquet')\n",
    "    (train,_) = training.randomSplit([0.01,0.99])\n",
    "    validation = spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_validation.parquet')\n",
    "    test = spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_test.parquet')\n",
    "\n",
    "    regParam_list = [0.01, 0.1, 1, 10.0, 100.0] #L2 regularization parameter\n",
    "    rank_list = [50, 100, 200, 300] #number of latent factors in model\n",
    "    #numBlocks_list=[10]    #adjust this to optimize parallel computation\n",
    "    alpha_list = [1.0] #alpha parameter\n",
    "    \n",
    "    error_list = []\n",
    "    model_list=[]\n",
    "\n",
    "    print(f'Pre string-indexing.')\n",
    "\n",
    "    #training data string indexer coversion on user_num column\n",
    "    user_indexer = StringIndexer(inputCol = \"user_id\", outputCol = \"user_num\", handleInvalid = \"skip\").fit(train)\n",
    "    track_indexer = StringIndexer(inputCol = \"track_id\", outputCol = \"track_num\", handleInvalid = \"skip\").fit(train)\n",
    "\n",
    "    train_idx = user_indexer.transform(train)\n",
    "    train_idx = track_indexer.transform(train_idx)\n",
    "    \n",
    "    val_idx = user_indexer.transform(validation)\n",
    "    val_idx = track_indexer.transform(val_idx)\n",
    "\n",
    "    test_idx = user_indexer.transform(test)\n",
    "    test_idx = track_indexer.transform(test_idx)\n",
    "\n",
    "    print(\"Setup complete, fitting models.\")\n",
    "\n",
    "    #different combinations of hyperparameters\n",
    "    grid = list(itertools.product(rank_list, regParam_list, alpha_list))\n",
    "\n",
    "    #filter users from training set who are also in val and test set \n",
    "    unique_users=val_idx.select('user_num').distinct()\n",
    "    \n",
    "    for rank, reg, alph in grid:\n",
    "        #train model using current hyperparameters\n",
    "        als_model = ALS(regParam=reg, rank = rank, userCol=\"user_num\", itemCol=\"track_num\", ratingCol=\"count\", coldStartStrategy=\"drop\", alpha=alph)\n",
    "        model = als_model.fit(train_idx)\n",
    "        model_list.append(model)\n",
    "\n",
    "        #run model on validation set\n",
    "        val_pred = model.transform(val_idx)\n",
    "        evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"count\", predictionCol=\"prediction\")\n",
    "        \n",
    "        #rmse = root mean squared error, determine it on the res of val w/ this model\n",
    "        rmse = evaluator.evaluate(val_pred)\n",
    "        error_list.append(rmse)\n",
    "        \n",
    "        print (\"---------Hyperparameter Tuning---------\")\n",
    "        print (\"regParam = \", reg, \"rank = \", rank)\n",
    "        print(\"Root-mean-square error = \" + str(rmse))\n",
    "    \n",
    "    #Best hyperparameter?\n",
    "    min_error = min(error_list)\n",
    "    print(\"Minimum error:\", min_error)\n",
    "    print(\"Hyperparameters:\", grid[error_list.index(min_error)])\n",
    "    best_model=model_list[error_list.index(min_error)]\n",
    "    \n",
    "    #get the top 500 song recommendations for each user? \n",
    "    userRecs=best_model.recommendForUserSubset(unique_users, 500)\n",
    "    userRecs.limit(10).show()\n",
    "\n",
    "    #interpretable format of recommendations (shows user_id, track_id, rating)\n",
    "    userRecs= userRecs.withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('user_id', col(\"rec_exp.track_id\"), col(\"rec_exp.rating\"))\n",
    "    #incorporate MAP estimator here? \n",
    "\n",
    "    #top 500 items for each user\n",
    "    #parquet file into a dataframe?\n",
    "    #val_with_pred=pd.concat([validation, val_pred]) \n",
    "    #top500=val_with_pred.groupby(['user_id', 'track_id'])['count'].sum()\n",
    "    #top500=top500.to_frame().groupby(['track_id]).head(500)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create the spark session object\n",
    "    spark = SparkSession.builder.appName('part1').getOrCreate()\n",
    "\n",
    "    #If you wish to command line arguments, look into the sys library(primarily sys.argv)\n",
    "    #Details are here: https://docs.python.org/3/library/sys.html\n",
    "    #If using command line arguments, be sure to add them to main function\n",
    "    netID = getpass.getuser()\n",
    "\n",
    "    # Call our main routine\n",
    "    main(spark, netID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extension 1 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-820942a6-dc2a-42b5-a8af-b5cd6f91c093",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run final code in peel cluster\n",
    "#Run numpy code in greene cluster\n",
    "#**Set up source shell_setup.sh in repo**\n",
    "#hdfs:/user/bm106/pub/MSD\n",
    "#Go under correct directory\n",
    "#spark-submit rec_sys.py --conf \"spark.blacklist.enabled=false\"\n",
    "#spark-submit --driver-memory=4g --executor-memory=4g --executor-cores=50 'pyfile'\n",
    "#conf.set(\"spark.blacklist.enabled\",\"false\") #if in code itself\n",
    "import sys\n",
    "import getpass \n",
    "import random\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.evaluation import RankingMetrics #May want to use MAP\n",
    "from pyspark.ml.evaluation import RegressionEvaluator #RMSE\n",
    "from pyspark.ml.recommendation import ALS #Alternating least squares\n",
    "from pyspark.sql import Row, Window\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import explode, col, expr\n",
    "import pyspark.sql.functions as pyF\n",
    "\n",
    "def main (spark, netID):\n",
    "    training=spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_train_new.parquet')\n",
    "    (train,_) = training.randomSplit([0.01,0.99])\n",
    "    validation = spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_validation.parquet')\n",
    "    test = spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_test.parquet')\n",
    "\n",
    "    #user_id, count, track_id\n",
    "    #group on track_id add the counts\n",
    "    #sort by count descending\n",
    "\n",
    "    prediction = train.groupBy('track_id').agg({'count':'mean'})\n",
    "    \n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"count\", predictionCol=\"avg(count)\")\n",
    "    #take track id from validation and take track id from prediciton and  use  mean from prediction as result\n",
    "    #want user_id, rating, track_id, mean(counts)\n",
    "\n",
    "    val_pred = validation.join(prediction, on='track_id')\n",
    "    rmse_val = evaluator.evaluate(val_pred)\n",
    "    print('RMSE on the validation set ' + str(rmse_val))\n",
    "\n",
    "    test_pred = test.join(prediction, on='track_id')\n",
    "    rmse_test = evaluator.evaluate(test_pred)\n",
    "    print('RMSE on the test set ' + str(rmse_test))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create the spark session object\n",
    "    spark = SparkSession.builder.appName('part1').getOrCreate()\n",
    "\n",
    "    #If you wish to command line arguments, look into the sys library(primarily sys.argv)\n",
    "    #Details are here: https://docs.python.org/3/library/sys.html\n",
    "    #If using command line arguments, be sure to add them to main function\n",
    "    netID = getpass.getuser()\n",
    "\n",
    "    # Call our main routine\n",
    "    main(spark, netID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-23d03a23-6718-4ea8-a16b-a0beaba32d5a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "ParamGridBuilder() hyperparameter tuning in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-ceb648fb-a9ac-4d4b-840e-87172da5106c",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Your recommendation model should use Spark's alternating least squares (ALS) method to learn latent factor representations for users and items.\n",
    "\n",
    "#user_id  | count | track_id   \n",
    "\n",
    "#Run final code in peel cluster\n",
    "#Run numpy code in greene cluster\n",
    "#**Set up source shell_setup.sh in repo**\n",
    "#hdfs:/user/bm106/pub/MSD\n",
    "#Go under correct directory\n",
    "#spark-submit rec_sys.py --conf \"spark.blacklist.enabled=false\"\n",
    "#spark-submit --driver-memory=4g --executor-memory=4g --executor-cores=50 'pyfile'\n",
    "#conf.set(\"spark.blacklist.enabled\",\"false\") #if in code itself\n",
    "import sys\n",
    "import getpass \n",
    "import random\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.evaluation import RankingMetrics #May want to use MAP\n",
    "from pyspark.ml.evaluation import RegressionEvaluator #RMSE\n",
    "from pyspark.ml.recommendation import ALS #Alternating least squares\n",
    "from pyspark.sql import Row, Window\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import explode, col, expr\n",
    "import pyspark.sql.functions as pyF\n",
    "\n",
    "def main (spark, netID):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    spark : SparkSession object\n",
    "    netID : string, netID of student to find files in HDFS\n",
    "    '''\n",
    "    training=spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_train_new.parquet')\n",
    "    (train,_) = training.randomSplit([0.25,0.75])\n",
    "    validation = spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_validation.parquet')\n",
    "    test = spark.read.parquet('hdfs:/user/bm106/pub/MSD/cf_test.parquet')\n",
    "\n",
    "    print('Pre string-indexing.')\n",
    "\n",
    "    #training data string indexer coversion on user_num column\n",
    "    user_indexer = StringIndexer(inputCol = \"user_id\", outputCol = \"user_num\", handleInvalid = \"skip\").fit(train)\n",
    "    track_indexer = StringIndexer(inputCol = \"track_id\", outputCol = \"track_num\", handleInvalid = \"skip\").fit(train)\n",
    "\n",
    "    train_idx = user_indexer.transform(train)\n",
    "    train_idx = track_indexer.transform(train_idx)\n",
    "    \n",
    "    val_idx = user_indexer.transform(validation)\n",
    "    val_idx = track_indexer.transform(val_idx)\n",
    "\n",
    "    test_idx = user_indexer.transform(test)\n",
    "    test_idx = track_indexer.transform(test_idx)\n",
    "\n",
    "    print(\"Setup complete, fitting models.\")\n",
    "    \n",
    "    #Hyperparameter tuning in parallel\n",
    "    als_model = ALS(userCol=\"user_num\", itemCol=\"track_num\", ratingCol=\"count\", coldStartStrategy=\"drop\")\n",
    "\n",
    "    ranks = [200, 225, 250, 275, 300]\n",
    "    regParams = [10, 1.0, 0.5, 0.1, 0.01]\n",
    "\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(als_model.rank, ranks) \\\n",
    "        .addGrid(als_model.regParam, regParams) \\\n",
    "        .build()\n",
    "\n",
    "    print (\"Num models tested: \", len(paramGrid))\n",
    "\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"count\", predictionCol=\"prediction\")\n",
    "\n",
    "    nF = 5 #NumFolds\n",
    "    parallelism = 6 #number of cores to run on... seemed like we get 6\n",
    "\n",
    "    cv = CrossValidator(estimator = als_model, estimatorParamMaps = paramGrid, evaluator = evaluator, numFolds = nF, parallelism = parallelism)\n",
    "\n",
    "    model = cv.fit(train_idx)\n",
    "    best_model = model.bestModel\n",
    "\n",
    "    print(\"Best RegParam:\", best_model._java_obj.parent().getRegParam())\n",
    "    print(\"Best Rank:\", best_model._java_obj.parent().getRank())\n",
    "\n",
    "    model = ALS(userCol=\"user_num\", itemCol=\"track_num\", ratingCol=\"count\", coldStartStrategy=\"drop\", rank=300, regParam=1.0)\n",
    "    best_model = model.fit(train_idx)\n",
    "    #Fit on test and validation set\n",
    "    val_pred = best_model.transform(val_idx)\n",
    "    rmse_val = evaluator.evaluate(val_pred)\n",
    "    print('RMSE on the validation set ' + str(rmse_val))\n",
    "\n",
    "    test_pred = best_model.transform(test_idx)\n",
    "    rmse_test = evaluator.evaluate(test_pred)\n",
    "    print('RMSE on the test set ' + str(rmse_test))\n",
    "    \n",
    "    #filter users from training set who are also in val and test set \n",
    "    unique_users_val = val_idx.select('user_num').distinct()\n",
    "    unique_users_test = test_idx.select('user_num').distinct()\n",
    "    unique_users_train =  train_idx.select('user_num').distinct()\n",
    "\n",
    "    #unique_users=[users if users is in unique_users_val and unique_users_test for users in unique_users_train]\n",
    "        \n",
    "    #get the top 500 song recommendations for each user (prediction)\n",
    "    userRecs=best_model.recommendForUserSubset(unique_users_test, 500)\n",
    "    track_df = Window.partitionBy('user_num').orderBy(col('count').desc())\n",
    "    RealTop500=test_idx.withColumn('rank', pyF.rank().over(track_df))\\\n",
    "    .where('rank <= {0}'.format(500)).groupBy('user_num').agg(expr('collect_list(track_num) as actual_track_lists'))\n",
    "    \n",
    "    RealAndPredict = RealTop500.join(userRecs, 'user_num').\\\n",
    "    rdd.map(lambda x: ([rec.track_num for rec in x['recommendations']], x['actual_track_lists']))\n",
    "    \n",
    "    RealAndPredict.limit(10).show()\n",
    "\n",
    "    #incorporate MAP estimator here? \n",
    "\n",
    "    #convert the df into csv file\n",
    "    RealAndPredict.write.csv('RealAndPredict_outputs.csv')\n",
    "    #top 500 items for each user\n",
    "    #parquet file into a dataframe?\n",
    "    #val_with_pred=pd.concat([validation, val_pred]) \n",
    "    #top500=val_with_pred.groupby(['user_id', 'track_id'])['count'].sum()\n",
    "    #top500=top500.to_frame().groupby(['track_id]).head(500)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create the spark session object\n",
    "    spark = SparkSession.builder.appName('part1').getOrCreate()\n",
    "\n",
    "    #If you wish to command line arguments, look into the sys library(primarily sys.argv)\n",
    "    #Details are here: https://docs.python.org/3/library/sys.html\n",
    "    #If using command line arguments, be sure to add them to main function\n",
    "    netID = getpass.getuser()\n",
    "\n",
    "    # Call our main routine\n",
    "    main(spark, netID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extension 2, UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-6cf9672a-b96f-423a-8624-3780e243d92b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 426,
    "execution_start": 1621130731464,
    "source_hash": "f558c6fa",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a07652ce7e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extension - UMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "# Extension - UMAP Visualization\n",
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('merged.csv', header = None)\n",
    "\n",
    "data.columns = ['users', 'tracks', 'pred']\n",
    "\n",
    "data = data.pivot_table(index=['users'], \n",
    "            columns=['tracks'], values='pred').fillna(0)\n",
    "\n",
    "data = data.to_numpy()\n",
    "data1 = data[:,1:]\n",
    "users = np.unique(data[:,0])\n",
    "fit = umap.UMAP()\n",
    "u = fit.fit_transform(data1)\n",
    "plt.scatter(\n",
    "    u[:, 0],\n",
    "    u[:, 1],\n",
    "    c='black')\n",
    "\n",
    "#using first 10 columns\n",
    "data1 = data[:,1:10]\n",
    "users = np.unique(data[:,0])\n",
    "fit = umap.UMAP()\n",
    "u = fit.fit_transform(data1)\n",
    "plt.scatter(\n",
    "    u[:, 0],\n",
    "    u[:, 1],\n",
    "    c='black')"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "12328efa-200a-47a9-8700-57c5c5a23374",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
